# AI System Implementation Plan

*Status: Ready for Implementation*

## Overview

This document provides a step-by-step implementation plan to build the simulation-based AI system described in the previous documents. We'll start by completely replacing the existing AI with a minimal mock system, then gradually implement real functionality.

## Current State Analysis

### Existing AI Files to Remove/Replace
- `internal/ai/ai.go` - Current AI decision logic
- `internal/ai/metrics/damage_done.go` - Partially updated, needs complete rewrite
- `internal/ai/metrics/friendly_fire.go` - Needs updating to new interface
- `internal/ai/metrics/movement.go` - Needs updating to new interface
- `internal/ai/metrics/plan.go` - Needs updating to new interface
- `internal/ai/metrics/metric.go` - Interface already updated

### Integration Points to Verify
- `internal/demo/demo.go` - How AI is called
- `cmd/gui/main.go` - AI integration in game loop
- `internal/ai/ai.go` - `Play()` function usage

## Implementation Steps

### Step 1: Clean Slate - Remove Existing AI
**Goal**: Remove all existing AI code and create minimal mock that prevents crashes

**Actions**:
1. Delete all files in `internal/ai/metrics/` except `metric.go`
2. Replace `internal/ai/ai.go` with minimal mock implementation
3. Verify game still runs without crashes
4. AI should do absolutely nothing (skip turns)

**Acceptance Criteria**:
- ✅ Game starts and runs combat
- ✅ AI turns are skipped (no actions taken)
- ✅ No compilation errors
- ✅ No runtime crashes during AI turns

**Code Changes**:
```go
// internal/ai/ai.go - Replace entire file
package ai

import "anvil/internal/core"

func Play(state *core.GameState) {
    // Mock: Do nothing, just end turn
    state.Encounter.EndTurn()
}
```

### Step 2: Basic Infrastructure - Hardcoded Attack
**Goal**: Create minimal infrastructure that makes AI always attack the first available enemy

**Actions**:
1. Create basic archetype system with hardcoded Berserker type
2. Create mock damage metric that returns hardcoded values
3. Implement minimal decision flow that always picks first attack action
4. Force demo to place creatures in melee range

**Acceptance Criteria**:
- ✅ AI always chooses to attack when attack is available
- ✅ AI attacks the first enemy it can reach
- ✅ Berserker archetype exists and is assigned to zombies
- ✅ Hardcoded damage metric returns fixed values
- ✅ No crashes, predictable behavior

**Code Changes**:
```go
// internal/ai/archetype.go - New file
package ai

type AIArchetype struct {
    Name    string
    Weights map[string]float32
}

var BerserkerArchetype = AIArchetype{
    Name: "berserker",
    Weights: map[string]float32{
        "damage_enemy":    2.0,
        "friendly_fire":   0.5,
        "survival_threat": 0.3,
    },
}

// internal/ai/metrics/damage.go - New file
package metrics

import (
    "anvil/internal/core"
    "anvil/internal/grid"
)

type DamageMetric struct{}

func (d DamageMetric) Evaluate(world *core.World, actor *core.Actor, action core.Action, target grid.Position, affected []grid.Position) map[string]int {
    // Mock: Return hardcoded values
    return map[string]int{
        "damage_enemy":  25,
        "friendly_fire": 0,
        "kill_potential": 10,
    }
}

// internal/ai/ai.go - Updated
package ai

import (
    "anvil/internal/core"
    "anvil/internal/ai/metrics"
)

func Play(state *core.GameState) {
    defer state.Encounter.EndTurn()
    
    actor := state.Encounter.ActiveActor()
    if !actor.CanAct() {
        return
    }
    
    // Mock: Find first attack action
    for _, action := range actor.Actions {
        if action.Tags().HasTag(tags.Attack) {
            validPositions := action.ValidPositions(actor.Position)
            if len(validPositions) > 0 {
                action.Perform([]grid.Position{validPositions[0]})
                return
            }
        }
    }
    
    // No valid attacks, skip turn
}
```

### Step 3: Archetype Weight System
**Goal**: Implement real archetype system with weight application

**Actions**:
1. Add archetype assignment to Actor
2. Implement weight aggregation system
3. Create Berserker and Defensive archetypes with different weights
4. Test that different archetypes behave differently

**Acceptance Criteria**:
- ✅ Actors have archetype assignments
- ✅ Weight aggregation converts raw metrics to final scores
- ✅ Berserker and Defensive archetypes defined with different weights
- ✅ Different archetypes produce different action scores (visible in logs)
- ✅ AI still makes reasonable attack decisions

**Code Changes**:
```go
// internal/core/actor.go - Add archetype field
type Actor struct {
    // ... existing fields ...
    AIArchetype *ai.AIArchetype  // Add this field
}

// internal/ai/scoring.go - New file
package ai

func ApplyArchetypeWeights(rawMetrics map[string]int, archetype *AIArchetype) int {
    finalScore := 0
    
    for metricName, rawValue := range rawMetrics {
        weight := archetype.Weights[metricName]
        if weight == 0 {
            weight = 1.0  // Default weight
        }
        
        weightedScore := int(float32(rawValue) * weight)
        finalScore += weightedScore
    }
    
    return finalScore
}
```

### Step 4: Multiple Actions Support
**Goal**: AI evaluates all available actions and picks the best one based on scores

**Actions**:
1. Evaluate all available actions, not just first attack
2. Apply archetype weights to each action
3. Select highest-scoring action
4. Add basic logging to show decision reasoning

**Acceptance Criteria**:
- ✅ AI evaluates all available actions (attacks, movement, etc.)
- ✅ AI picks highest-scoring action
- ✅ Different archetypes pick different actions in same situation
- ✅ Debug logs show action scores and selection reasoning
- ✅ AI behavior is consistent and predictable

**Code Changes**:
```go
// internal/ai/ai.go - Updated decision flow
func Play(state *core.GameState) {
    defer state.Encounter.EndTurn()
    
    actor := state.Encounter.ActiveActor()
    if !actor.CanAct() {
        return
    }
    
    bestAction, bestPosition := findBestAction(state.World, actor)
    if bestAction != nil {
        bestAction.Perform([]grid.Position{bestPosition})
    }
}

func findBestAction(world *core.World, actor *core.Actor) (core.Action, grid.Position) {
    bestScore := math.MinInt
    var bestAction core.Action
    var bestPosition grid.Position
    
    for _, action := range actor.Actions {
        validPositions := action.ValidPositions(actor.Position)
        for _, pos := range validPositions {
            score := evaluateAction(world, actor, action, pos)
            if score > bestScore {
                bestScore = score
                bestAction = action
                bestPosition = pos
            }
        }
    }
    
    return bestAction, bestPosition
}
```

### Step 5: Real Damage Metric
**Goal**: Replace hardcoded damage metric with real calculations

**Actions**:
1. Implement real damage calculations based on action and targets
2. Add line-of-sight checking
3. Distinguish between enemy and ally damage
4. Add kill potential calculations

**Acceptance Criteria**:
- ✅ Damage metric calculates real damage values based on action.AverageDamage()
- ✅ Line-of-sight checking works correctly
- ✅ Enemy damage is positive, ally damage is negative
- ✅ Kill potential bonus is applied when damage >= target HP
- ✅ AI preferentially targets enemies it can kill

**Code Changes**:
```go
// internal/ai/metrics/damage.go - Real implementation
func (d DamageMetric) Evaluate(world *core.World, actor *core.Actor, action core.Action, target grid.Position, affected []grid.Position) map[string]int {
    results := map[string]int{}
    damage := action.AverageDamage()
    
    if damage == 0 {
        return results
    }
    
    for _, pos := range affected {
        targetActor := world.ActorAt(pos)
        if targetActor == nil || targetActor.IsDead() {
            continue
        }
        
        if !world.HasLineOfSight(actor.Position, pos) {
            continue
        }
        
        actualDamage := min(damage, targetActor.HitPoints)
        
        if actor.IsHostileTo(targetActor) {
            results["damage_enemy"] += actualDamage
            
            if damage >= targetActor.HitPoints {
                results["kill_potential"] += 15
            }
        } else {
            results["friendly_fire"] -= actualDamage * 2
        }
    }
    
    return results
}
```

### Step 6: Basic Positioning Metric
**Goal**: Add survival threat assessment to make AI avoid dangerous positions

**Actions**:
1. Implement positioning metric that evaluates immediate threats
2. Add survival threat calculation (negative for dangerous positions)
3. Test that Defensive archetype avoids danger more than Berserker
4. Ensure AI considers positioning when choosing actions

**Acceptance Criteria**:
- ✅ Positioning metric calculates threat level at target position
- ✅ Dangerous positions get negative survival_threat scores
- ✅ Defensive archetype avoids dangerous positions more than Berserker
- ✅ AI considers both damage potential and safety when choosing actions
- ✅ Observable behavioral difference between archetypes

**Code Changes**:
```go
// internal/ai/metrics/positioning.go - New file
package metrics

import (
    "anvil/internal/core"
    "anvil/internal/grid"
)

type PositioningMetric struct{}

func (p PositioningMetric) Evaluate(world *core.World, actor *core.Actor, action core.Action, target grid.Position, affected []grid.Position) map[string]int {
    results := map[string]int{}
    
    // Threat assessment - how dangerous is this position?
    nearbyEnemies := world.ActorsInRange(target, 2, func(a *core.Actor) bool {
        return a.IsHostileTo(actor)
    })
    
    threatLevel := 0
    for _, enemy := range nearbyEnemies {
        // Simple threat calculation based on enemy HP
        threatLevel += enemy.MaxHitPoints / 4
    }
    
    results["survival_threat"] = -threatLevel  // Negative because threat is bad
    
    return results
}
```

### Step 7: Target Selection Enhancement
**Goal**: AI chooses optimal targets, not just first available

**Actions**:
1. Evaluate all possible targets for each action
2. Consider target priority (wounded enemies, dangerous enemies)
3. Implement action-target combination evaluation
4. Test that AI preferentially finishes off wounded enemies

**Acceptance Criteria**:
- ✅ AI evaluates all possible targets for each action
- ✅ AI preferentially targets wounded enemies it can kill
- ✅ AI considers target threat level in selection
- ✅ Action-target combinations are evaluated properly
- ✅ Observably better target selection behavior

### Step 8: Position Optimization
**Goal**: AI considers different positions to cast/attack from, not just current position

**Actions**:
1. For each action, evaluate possible casting positions
2. Temporarily move actor to evaluate position safety
3. Select optimal position for each action
4. Integrate position optimization into decision flow

**Acceptance Criteria**:
- ✅ AI evaluates multiple casting positions for each action
- ✅ AI chooses safer positions when possible
- ✅ Position optimization affects action selection
- ✅ AI moves to better positions before attacking when beneficial
- ✅ No infinite loops or crashes from position evaluation

### Step 9: Movement Actions and Fallback
**Goal**: AI can move to better positions when no good attacks are available

**Actions**:
1. Add evaluation of pure movement actions
2. Implement fallback behavior when no actions score positively
3. Add movement efficiency calculations
4. Test fallback positioning behavior

**Acceptance Criteria**:
- ✅ AI evaluates movement actions alongside attack actions
- ✅ AI moves to better positions when no good attacks available
- ✅ Movement efficiency is considered in scoring
- ✅ Fallback behavior is graceful and sensible
- ✅ AI doesn't get stuck in infinite movement loops

### Step 10: System Integration and Testing
**Goal**: Full system testing with multiple archetypes and complex scenarios

**Actions**:
1. Test with multiple creatures of different archetypes
2. Verify behavioral differentiation is clear and consistent
3. Performance testing and optimization
4. Add comprehensive logging and debugging tools

**Acceptance Criteria**:
- ✅ Multiple archetypes behave distinctly different
- ✅ AI makes sensible decisions in complex scenarios
- ✅ Performance is acceptable (turns complete in <100ms)
- ✅ No crashes or infinite loops in any tested scenario
- ✅ Debugging tools allow inspection of AI decision reasoning

## Validation Tests

### Behavioral Tests (Run after each step)
1. **Aggression Test**: Berserker should engage enemies more readily than Defensive
2. **Safety Test**: Defensive should retreat/avoid danger more than Berserker  
3. **Target Priority Test**: AI should preferentially target wounded enemies
4. **Position Test**: AI should consider tactical positioning
5. **Fallback Test**: AI should move to better positions when stuck

### Technical Tests
1. **Performance Test**: Each turn should complete in reasonable time
2. **Stability Test**: No crashes during extended play
3. **Memory Test**: No memory leaks during extended play
4. **Edge Case Test**: Graceful handling of unusual scenarios

## Phase 1 Success Criteria

By the end of Step 10, we should have:
- ✅ **Working AI system** following the 7-step Larian flow
- ✅ **3 core weights** implemented: damage_enemy, friendly_fire, survival_threat
- ✅ **2 metrics** working: Damage and Positioning
- ✅ **3 archetypes** with observable behavioral differences
- ✅ **Stable foundation** for Phase 2 expansion

## Next Phase Preparation

After Phase 1 completion:
- **Phase 2**: Add kill_potential, tactical_position, movement_efficiency weights
- **Phase 3**: Add Control and Healing metrics
- **Phase 4**: Add Target Priority and advanced features

This implementation plan provides a concrete path from the current broken AI to a working Phase 1 system, with clear validation criteria at each step.